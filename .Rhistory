#' @param x a word embedding
#' @return normalized (unit) vector/word embedding.
#' @noRd
normalizeV <- function(x) {
magnitude <-
x / sqrt(sum(x^2, na.rm = TRUE))
}
#' Function to take min, max, mean or the CLS
#' (which comes from BERT models; not Static spaces) from list of vectors
#' @param x word embeddings to be aggregated
#' @param aggregation method to carry out the aggregation, including "min", "max" and "mean" which takes the
#' minimum, maximum or mean across each column; or "concatenate", which links together each word embedding layer
#' to one long row.
#' @return aggregated word embeddings.
#' @importFrom tibble as_tibble_row
#' @importFrom purrr map
#' @noRd
textEmbeddingAggregation <- function(x, aggregation = "min") {
if (aggregation == "min") {
min_vector <- unlist(purrr::map(x, min, na.rm = TRUE))
min_vector
} else if (aggregation == "max") {
max_vector <- unlist(purrr::map(x, max, na.rm = TRUE))
max_vector
} else if (aggregation == "mean") {
mean_vector <- colMeans(x, na.rm = TRUE)
mean_vector
} else if (aggregation == "concatenate") {
long_vector <- c(t(x)) %>% tibble::as_tibble_row(.name_repair = "minimal")
colnames(long_vector) <- paste0("Dim", sep = "", seq_len(length(long_vector)))
variable_name <- names(x)[1]
# If original name is not just Dim1, then add back Dim1_variable.name
if (!variable_name == "Dim1") {
variable_name <- sub(".*Dim1_", "", variable_name)
colnames(long_vector) <- paste0(
names(long_vector),
"_",
variable_name
)
}
long_vector
} else if (aggregation == "normalize") {
sum_vector <- unlist(purrr::map(x, sum, na.rm = TRUE))
normalized_vector <- normalizeV(sum_vector)
normalized_vector
}
}
#' where all text is transformed to lowercase and tokenized.
#' Also give word frequencies.
#' @param x_characters A character column in a tibble.
#' @param hg_tokenizer (boolean) Weather to use textTokenize
#' @return A tibble with a unique words column and a column with their respective frequency.
#' @importFrom tibble tibble
#' @importFrom stringi stri_c stri_trans_tolower
# @importFrom stringr str_c str_split stri_split_boundaries
# @importFrom tokenizers tokenize_words
#' @noRd
getUniqueWordsAndFreq <- function(x_characters, hg_tokenizer = NULL, ...) {
if (is.null(hg_tokenizer)) {
# Unite all text variables into one
x_characters2 <- tidyr::unite(x_characters, "x_characters2", seq_len(ncol(x_characters)), sep = " ")
# unite all rows in the column into one cell
x_characters3 <- stringi::stri_c(x_characters2$x_characters2, collapse = " ")
# Tokenize into single words help(stri_split_boundaries)
x_characters4a <- stringi::stri_trans_tolower(x_characters3)
x_characters4b <- stringi::stri_split_boundaries(x_characters4a,
type = "word",
skip_word_none = TRUE,
skip_word_number = FALSE
)[[1]]
# Create dataframe with single words and frequency
x_characters5 <- data.frame(sort(table(unlist(strsplit(tolower(x_characters4b), " ")))))
}
if (!is.null(hg_tokenizer)) {
x_characters4b <- lapply(list(x_characters), textTokenize, model = hg_tokenizer, ...)
x_characters5 <- data.frame(sort(table(unlist(x_characters4b))))
}
if (length(x_characters5) == 1) {
colnames(x_characters5) <- c("Freq")
x_characters5 <- tibble::rownames_to_column(x_characters5, "Var1")
}
singlewords <- tibble::tibble(x_characters5$Var1, x_characters5$Freq)
colnames(singlewords) <- c("words", "n")
singlewords$words <- as.character(singlewords$words)
return(singlewords)
}
#' This is a function that sorts out (i.e., tidy) the embeddings from the huggingface interface.
#' @param x list of layers.
#' @param layers the number of layers to get (setting comes from textEmbedRawLayers).
#' @param return_tokens bolean whether tokens have been returned (setting comes from textEmbedRawLayers).
#' @return Layers in tidy tibble format with each dimension column called Dim1, Dim2 etc.
#' @noRd
sortingLayers <- function(x,
layers = layers,
return_tokens = return_tokens) {
# If selecting "all" layers, find out number of layers to help indicate layer index later in code
if (is.character(layers)) {
layers <- 0:(length(x[[1]][[1]]) - 1)
}
# Find number of dimensions (where the place differ depending on return_token is TRUE or FALSE)
if (return_tokens) {
dimensions <- length(x[[1]][[1]][[1]][[1]][[1]])
participants <- length(x[[1]])
} else {
dimensions <- length(x[[1]][[1]][[1]][[1]])
participants <- length(x)
}
# Tidy-structure tokens and embeddings
# Loop over the cases in the variable; i_in_variable = 1
variable_x <- list()
for (i_in_variable in 1:participants) {
if (return_tokens) {
tokens <- x[[2]][[i_in_variable]]
token_id <- seq_len(length(tokens))
all_layers <- x[[1]][[i_in_variable]]
} else {
tokens <- NULL
all_layers <- x[[i_in_variable]]
# Count number of embeddings within one layer
token_id <- seq_len(length(all_layers[[1]][[1]]))
}
# Loop of the number of layers; i_layers=1
layers_list <- list()
for (i_layers in seq_len(length(all_layers))) {
i_layers_for_tokens <- all_layers[i_layers]
# Transpose layers and give each column a DimX names
layers_4_token <- suppressMessages(t(dplyr::bind_cols(i_layers_for_tokens))) %>%
magrittr::set_colnames(c(paste0("Dim", 1:dimensions))) # %>%
layers_4_token <- tibble::as_tibble(layers_4_token)
if (return_tokens) {
tokens_layer_number <- tibble::tibble(tokens, token_id, rep(layers[i_layers], length(tokens)))
colnames(tokens_layer_number) <- c("tokens", "token_id", "layer_number")
# Bind tokens with word embeddings (not selecting <pad>s)
tokens_lnumber_layers <- dplyr::bind_cols(tokens_layer_number,
layers_4_token[1:nrow(tokens_layer_number),])
} else {
layer_number <- tibble::tibble(token_id, rep(layers[i_layers], nrow(layers_4_token)))
colnames(layer_number) <- c("token_id", "layer_number")
# Bind tokens with word embeddings (not selecting <pad>s)
tokens_lnumber_layers <- dplyr::bind_cols(layer_number,
layers_4_token[1:nrow(tokens_layer_number),])
}
layers_list[[i_layers]] <- tokens_lnumber_layers
layers_list
}
layers_tibble <- dplyr::bind_rows(layers_list)
variable_x[[i_in_variable]] <- layers_tibble
}
variable_x
}
#' This is a function that uses the textAggregation to aggregate the layers
#' @param x list of layers.
#' @param aggregation method to aggregate the layers.
#' @param return_tokens (boolean) returns the tokens as the first column.
#' @return Aggregated layers in tidy tibble format.
#' @noRd
layer_aggregation_helper <- function(x,
aggregation = aggregation,
return_tokens = FALSE) {
aggregated_layers_saved <- list()
# Get unique number of token ids in the variable starting with x$token_id ; i_token_id=1
number_of_ids <- unique(x[, grep("^token_id", names(x))][[1]])
# Loops over the number of tokens; i_token_id = 1
for (i_token_id in seq_len(length(number_of_ids))) {
# Selects all the layers for each token/token_id
x1 <- x[x[, grep("^token_id", names(x))][[1]] == i_token_id, ]
# Select only Dimensions
x2 <- dplyr::select(x1, dplyr::starts_with("Dim"))
# Aggregate the dimensions
x3 <- textEmbeddingAggregation(x2, aggregation = aggregation)
aggregated_layers_saved[[i_token_id]] <- x3
}
aggregated_layers_saved1 <- dplyr::bind_rows(aggregated_layers_saved)
if (return_tokens) {
# Number of ids
number_of_layers <- unique(x[, grep("^layer_number", names(x))][[1]])
n_layers <- length(number_of_layers)
tokens <- x$tokens[1:(length(x$tokens) / n_layers)]
tokens <- as_tibble_col(tokens, column_name = "tokens")
aggregated_layers_saved1 <- dplyr::bind_cols(tokens, aggregated_layers_saved1)
}
return(aggregated_layers_saved1)
}
#' grep_col_by_name_in_list
#' This function finds a column by name independent on where in the list structure it is.
#' @param l a list.
#' @param pattern what to find; such as the "layers_number" column.
#' @return elements in the column called pattern.
#' @noRd
grep_col_by_name_in_list <- function(l, pattern) {
u <- unlist(l)
u[grep(pattern, names(u))]
}
#' Options (ordered from less logging to more logging): critical, error, warning, info, debug
#' @return Returns tokens according to specified huggingface transformer.
#' @examples
#' \donttest{
#' # tokens <- textTokenize("hello are you?")
#' }
#' @seealso see \code{\link{textEmbed}}
#' @importFrom reticulate source_python
#' @importFrom tibble tibble as_tibble
#' @export
textTokenize <- function(texts,
model = "bert-base-uncased",
max_token_to_sentence = 4,
device = "cpu",
tokenizer_parallelism = FALSE,
model_max_length = NULL,
logging_level = "error") {
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("python",
"huggingface_Interface3.py",
# envir = NULL,
package = "text",
mustWork = TRUE
))
tokens <- hgTokenizerGetTokens(
text_strings = texts,
model = model,
max_token_to_sentence = max_token_to_sentence,
device = device,
tokenizer_parallelism = tokenizer_parallelism,
model_max_length = model_max_length,
logging_level = logging_level
)
tokens1 <- lapply(tokens, tibble::as_tibble_col, column_name = "tokens")
return(tokens1)
}
if (is.numeric(layers)) {
if (max(layers) > textModelLayers(model)) {
stop("You are trying to extract layers that do not exist in this model.")
}
}
if (layers[1] < 0) {
n <- textModelLayers("bert-base-uncased")
layers <- 1 + n + layers
layers
}
# Select all character variables and make them UTF-8 coded (e.g., BERT wants it that way).
data_character_variables <- select_character_v_utf8(texts)
x <- data_character_variables
sorted_layers_ALL_variables <- list()
sorted_layers_ALL_variables$context_tokens <- list()
# Loop over all character variables; i_variables = 1
T_test1 <- Sys.time()
T1_variable <- Sys.time()
# Python file function to HuggingFace
hg_embeddings <- hgTransformerGetEmbedding(
text_strings = x[[i_variables]],
model = model,
layers = layers,
return_tokens = return_tokens,
device = device,
tokenizer_parallelism = tokenizer_parallelism,
model_max_length = model_max_length,
max_token_to_sentence = max_token_to_sentence,
logging_level = logging_level
)
i_variables = 1
# Python file function to HuggingFace
hg_embeddings <- hgTransformerGetEmbedding(
text_strings = x[[i_variables]],
model = model,
layers = layers,
return_tokens = return_tokens,
device = device,
tokenizer_parallelism = tokenizer_parallelism,
model_max_length = model_max_length,
max_token_to_sentence = max_token_to_sentence,
logging_level = logging_level
)
T_test2 <- Sys.time()
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("/Users/oscarkjell/Desktop/1 Projects/0 Research/0 text r-package/text/inst/python",
"sorting_py.py",
# envir = NULL,
package = "text",
mustWork = TRUE
))
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("/Users/oscarkjell/Desktop/1 Projects/0 Research/0 text r-package/text/inst/python",
"sorting_py.py",
# envir = NULL,
# package = "text",
mustWork = TRUE
))
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("/Users/oscarkjell/Desktop/1 Projects/0 Research/0 text r-package/text/inst/python/sorting_py.py",
#"sorting_py.py",
# envir = NULL,
# package = "text",
mustWork = TRUE
))
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("python",
"sorting_py.py",
# envir = NULL,
package = "text",
mustWork = TRUE
))
T1_ok_test <- Sys.time()
variable_x <- sortingLayersPy(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
library(text)
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("python",
"sorting_py.py",
# envir = NULL,
package = "text",
mustWork = TRUE
))
T1_ok_test <- Sys.time()
variable_x <- sortingLayersPy(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
library(text)
variable_x <- sortingLayersPy(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("python",
"sorting_py.py",
# envir = NULL,
package = "text",
mustWork = TRUE
))
variable_x <- sortingLayersPy(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
library(text)
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("python",
"sorting_py.py",
# envir = NULL,
package = "text",
mustWork = TRUE
))
T1_ok_test <- Sys.time()
variable_x <- sortingLayersPy(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
library(text)
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("python",
"sorting_py.py",
# envir = NULL,
package = "text",
mustWork = TRUE
))
T1_ok_test <- Sys.time()
variable_x <- sortingLayersPy(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
library(text)
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("python",
"sorting_py.py",
# envir = NULL,
package = "text",
mustWork = TRUE
))
variable_x <- sortingLayersPy(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
library(text)
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("python",
"sorting_py.py",
# envir = NULL,
package = "text",
mustWork = TRUE
))
T1_ok_test <- Sys.time()
variable_x <- sortingLayersPy(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
library(text)
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("python",
"sorting_py.py",
# envir = NULL,
package = "text",
mustWork = TRUE
))
T1_ok_test <- Sys.time()
variable_x <- sortingLayersPy(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
layers
return_tokens
hg_embeddings
saveRDS(hg_embeddings, "hg_embeddings.rds")
Language_based_assessment_data_8[1][1]
texts = Language_based_assessment_data_8[1][[1]]
texts
texts = Language_based_assessment_data_8[1, 1]
texts
if (decontextualize == TRUE & word_type_embeddings == FALSE) {
stop(cat(
colourise("decontextualize = TRUE & word_type_embeddings = FALSE has not been implemented in textEmbedRawLayers() at this stage.",
fg = "red"),
colourise("When using decontextualize = TRUE  you need to create the word_type_embeddings. To create a text embeddings withouth it would take unnecessary
time as it would require to send the same decontextualised words to a transformer multiple times (whilst getting the same results over and over).
Consdier using rextEmbed, to get token embeddings as well as text embeddings.",
fg = "green")
))
}
# Run python file with HunggingFace interface to state-of-the-art transformers
reticulate::source_python(system.file("python",
"huggingface_Interface3.py",
# envir = NULL,
package = "text",
mustWork = TRUE
))
if (is.numeric(layers)) {
if (max(layers) > textModelLayers(model)) {
stop("You are trying to extract layers that do not exist in this model.")
}
}
if (layers[1] < 0) {
n <- textModelLayers("bert-base-uncased")
layers <- 1 + n + layers
layers
}
# Select all character variables and make them UTF-8 coded (e.g., BERT wants it that way).
data_character_variables <- select_character_v_utf8(texts)
x <- data_character_variables
sorted_layers_ALL_variables <- list()
sorted_layers_ALL_variables$context_tokens <- list()
# Loop over all character variables; i_variables = 1
T_test1 <- Sys.time()
# Python file function to HuggingFace
hg_embeddings <- hgTransformerGetEmbedding(
text_strings = x[[i_variables]],
model = model,
layers = layers,
return_tokens = return_tokens,
device = device,
tokenizer_parallelism = tokenizer_parallelism,
model_max_length = model_max_length,
max_token_to_sentence = max_token_to_sentence,
logging_level = logging_level
)
saveRDS(hg_embeddings, "hg_embeddings.rds")
hg_embeddings
sortingLayers
variable_x <- sortingLayers(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
library(tidyvers)
library(tidyverse)
variable_x <- sortingLayers(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
variable_x
texts = Language_based_assessment_data_8[1:2, 1:2]
if (is.numeric(layers)) {
if (max(layers) > textModelLayers(model)) {
stop("You are trying to extract layers that do not exist in this model.")
}
}
if (layers[1] < 0) {
n <- textModelLayers("bert-base-uncased")
layers <- 1 + n + layers
layers
}
# Select all character variables and make them UTF-8 coded (e.g., BERT wants it that way).
data_character_variables <- select_character_v_utf8(texts)
x <- data_character_variables
sorted_layers_ALL_variables <- list()
sorted_layers_ALL_variables$context_tokens <- list()
# Loop over all character variables; i_variables = 1
T_test1 <- Sys.time()
T1_variable <- Sys.time()
# Python file function to HuggingFace
hg_embeddings <- hgTransformerGetEmbedding(
text_strings = x[[i_variables]],
model = model,
layers = layers,
return_tokens = return_tokens,
device = device,
tokenizer_parallelism = tokenizer_parallelism,
model_max_length = model_max_length,
max_token_to_sentence = max_token_to_sentence,
logging_level = logging_level
)
T_test2 <- Sys.time()
hg_embeddings
variable_x <- sortingLayers(x = hg_embeddings,
layers = layers,
return_tokens = return_tokens)
variable_x
6*4.8
4*7.5
#  textModels()
#  unlink("./run_clf", recursive = TRUE)
text::textFineTuneTask(Language_based_assessment_data_8[,c("satisfactiontexts",
"gender")],
model_name_or_path = "distilbert-base-uncased",
is_regression = FALSE,
output_dir = "./run_clf",
label_names = c("male", "female"))
Language_based_assessment_data_8
Language_based_assessment_data_8
save_csv(Language_based_assessment_data_8, "Language_based_assessment_data_8.csv")
save.csv(Language_based_assessment_data_8, "Language_based_assessment_data_8.csv")
library(tidyverse)
save.csv(Language_based_assessment_data_8, "Language_based_assessment_data_8.csv")
save_csv(Language_based_assessment_data_8, "Language_based_assessment_data_8.csv")
write_csv(Language_based_assessment_data_8, "Language_based_assessment_data_8.csv")
